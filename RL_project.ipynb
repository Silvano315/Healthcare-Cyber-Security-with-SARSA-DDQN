{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# REINFORCEMENT LEARNING PROJECT\n",
    "*This is the notebook for the eighth project of the AI Engineering Master with Professio AI*\n",
    "\n",
    "It is organized in 2 sections:\n",
    "1. SARSA algorithm \n",
    "2. DDQN algorithm"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## IDS-Game Environment Exploration"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Import Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "from src.environment.explorer import IdsGameExplorer, IDSGAME_ENV_MAPPING"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Show the available environments"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Available IdsGame Environments:\n",
      "- idsgame-random-attack-v0\n",
      "- idsgame-maximal-attack-v0\n",
      "- idsgame-minimal-defense-v0\n",
      "- idsgame-random-defense-v0\n"
     ]
    }
   ],
   "source": [
    "print(\"Available IdsGame Environments:\")\n",
    "\n",
    "for env_name in IDSGAME_ENV_MAPPING.keys():\n",
    "    print(f\"- {env_name}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Environmental metric analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-11-14 16:39:35.347 Python[63556:20083486] ApplePersistenceIgnoreState: Existing state will not be touched. New state will be written to /var/folders/8d/09j2zdrx7klfl7nffqz630000000gn/T/org.python.python.savedState\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Environment Metrics:\n",
      "Number of nodes: 3\n",
      "Number of attack types: 10\n",
      "Maximum value: 9\n",
      "\n",
      "Defense position shape: (11,)\n",
      "Attack position shape: (11,)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/silvanoquarto/Desktop/PROJECTS/Master_AI_Engineering/Healthcare-Cyber-Security-with-SARSA-DDQN/.venv/lib/python3.12/site-packages/gymnasium/utils/passive_env_checker.py:181: DeprecationWarning: \u001b[33mWARN: Current gymnasium version requires that `Env.reset` can be passed `options` to allow the environment initialisation to be passed additional information.\u001b[0m\n",
      "  logger.deprecation(\n"
     ]
    }
   ],
   "source": [
    "explorer = IdsGameExplorer(\"idsgame-random-attack-v0\")\n",
    "\n",
    "metrics = explorer.get_environment_metrics()\n",
    "\n",
    "print(\"\\nEnvironment Metrics:\")\n",
    "print(f\"Number of nodes: {metrics.num_nodes}\")\n",
    "print(f\"Number of attack types: {metrics.num_attack_types}\")\n",
    "print(f\"Maximum value: {metrics.max_value}\")\n",
    "print(f\"\\nDefense position shape: {metrics.defense_position.shape}\")\n",
    "print(f\"Attack position shape: {metrics.attack_position.shape}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Analyse the space of actions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Action Space Analysis:\n",
      "type: <class 'gymnasium.spaces.discrete.Discrete'>\n",
      "shape: ()\n",
      "sample: 0\n",
      "n: 30\n"
     ]
    }
   ],
   "source": [
    "action_info = explorer.explore_action_space()\n",
    "\n",
    "print(\"\\nAction Space Analysis:\")\n",
    "for key, value in action_info.items():\n",
    "    print(f\"{key}: {value}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Explore some state transitions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-11-14 16:39:41.684 Python[63556:20083486] +[IMKClient subclass]: chose IMKClient_Modern\n",
      "2024-11-14 16:39:41.743 Python[63556:20083486] +[IMKInputSession subclass]: chose IMKInputSession_Modern\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Analyzing State Transitions:\n",
      "\n",
      "Step 1:\n",
      "Actions taken:\n",
      "  Attack: 0\n",
      "  Defense: 25\n",
      "Reward received: (0, 0)\n",
      "Episode terminated: False\n",
      "State changed: True\n",
      "\n",
      "Step 2:\n",
      "Actions taken:\n",
      "  Attack: 16\n",
      "  Defense: 11\n",
      "Reward received: (0, 0)\n",
      "Episode terminated: False\n",
      "State changed: True\n",
      "\n",
      "Step 3:\n",
      "Actions taken:\n",
      "  Attack: 19\n",
      "  Defense: 29\n",
      "Reward received: (0, 0)\n",
      "Episode terminated: False\n",
      "State changed: True\n",
      "\n",
      "Step 4:\n",
      "Actions taken:\n",
      "  Attack: 2\n",
      "  Defense: 20\n",
      "Reward received: (0, 0)\n",
      "Episode terminated: False\n",
      "State changed: True\n",
      "\n",
      "Step 5:\n",
      "Actions taken:\n",
      "  Attack: 24\n",
      "  Defense: 21\n",
      "Reward received: (0, 0)\n",
      "Episode terminated: False\n",
      "State changed: True\n"
     ]
    }
   ],
   "source": [
    "transitions = explorer.analyze_state_transition(num_steps=5, render=True)\n",
    "\n",
    "print(\"\\nAnalyzing State Transitions:\")\n",
    "for transition in transitions['transitions']:\n",
    "    print(f\"\\nStep {transition['step']}:\")\n",
    "    print(f\"Actions taken:\")\n",
    "    print(f\"  Attack: {transition['action']['attack']}\")\n",
    "    print(f\"  Defense: {transition['action']['defense']}\")\n",
    "    print(f\"Reward received: {transition['reward']}\")\n",
    "    print(f\"Episode terminated: {transition['terminated']}\")\n",
    "    print(f\"State changed: {transition['observation_change']}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Analysis of the reward mechanism"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Reward Mechanism Analysis:\n",
      "Average successful attack reward: 1.00\n",
      "Average failed attack penalty: -1.00\n",
      "Average defense reward: 0.12\n",
      "Average step penalty: 0.00\n"
     ]
    }
   ],
   "source": [
    "rewards = explorer.analyze_reward_mechanism(num_episodes=100)\n",
    "\n",
    "print(\"\\nReward Mechanism Analysis:\")\n",
    "print(f\"Average successful attack reward: {rewards.successful_attack_reward:.2f}\")\n",
    "print(f\"Average failed attack penalty: {rewards.failed_attack_penalty:.2f}\")\n",
    "print(f\"Average defense reward: {rewards.defense_reward:.2f}\")\n",
    "print(f\"Average step penalty: {rewards.step_penalty:.2f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Analysis of the game dynamics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Game Dynamics Analysis:\n",
      "Average episode length: 5.15 steps\n",
      "\n",
      "Win conditions: {'attack_successful': 15}\n",
      "Loss conditions: {'attack_failed': 85}\n",
      "\n",
      "Most common attack patterns: {(np.int64(19), np.int64(29), np.int64(21)): 1, (np.int64(16), np.int64(11), np.int64(24)): 1, (np.int64(25), np.int64(1), np.int64(17)): 1, (np.int64(28), np.int64(23), np.int64(4)): 1, (np.int64(1), np.int64(7), np.int64(24)): 1}\n"
     ]
    }
   ],
   "source": [
    "dynamics = explorer.analyze_game_dynamics(num_episodes=100) \n",
    "\n",
    "print(\"\\nGame Dynamics Analysis:\")\n",
    "print(f\"Average episode length: {dynamics.average_episode_length:.2f} steps\")\n",
    "print(\"\\nWin conditions:\", dynamics.win_conditions)\n",
    "print(\"Loss conditions:\", dynamics.loss_conditions)\n",
    "print(\"\\nMost common attack patterns:\", dynamics.common_attack_patterns)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Performance analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Performance Analysis:\n",
      "Average step time: 0.10 ms\n",
      "Memory usage (MB): 109.93 mean, 110.09 max\n",
      "Steps per second: 10372.95\n"
     ]
    }
   ],
   "source": [
    "performance = explorer.analyze_performance(num_steps=1000)  \n",
    "\n",
    "print(\"\\nPerformance Analysis:\")\n",
    "print(f\"Average step time: {performance.avg_step_time*1000:.2f} ms\")\n",
    "print(f\"Memory usage (MB): {performance.memory_usage['mean']:.2f} mean, \"\n",
    "      f\"{performance.memory_usage['max']:.2f} max\")\n",
    "print(f\"Steps per second: {performance.episode_statistics['steps_per_second']:.2f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## SARSA algorithm"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## DDQN algorithm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-11-13 11:43:37.928 Python[39060:16942726] ApplePersistenceIgnoreState: Existing state will not be touched. New state will be written to /var/folders/8d/09j2zdrx7klfl7nffqz630000000gn/T/org.python.python.savedState\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "=== Environment Information ===\n",
      "Observation Space Type: <class 'gymnasium.spaces.box.Box'>\n",
      "Action Space Type: <class 'gymnasium.spaces.discrete.Discrete'>\n",
      "Action Space: Discrete(30)\n",
      "\n",
      "=== Initial Observation ===\n",
      "Type: <class 'numpy.ndarray'>\n",
      "Shape: (3, 11)\n",
      "\n",
      "=== Testing Random Actions ===\n",
      "\n",
      "Step 1:\n",
      "Action taken - Attack: 9, Defense: 9\n",
      "Reward: (0, 0)\n",
      "Terminated: False\n",
      "Truncated: False\n",
      "Info: {'moved': False}\n",
      "New Observation Shape: (3, 11)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/silvanoquarto/Desktop/PROJECTS/Master_AI_Engineering/Healthcare-Cyber-Security-with-SARSA-DDQN/.venv/lib/python3.12/site-packages/gymnasium/utils/passive_env_checker.py:175: UserWarning: \u001b[33mWARN: The default seed argument in `Env.reset` should be `None`, otherwise the environment will by default always be deterministic. Actual default: seed: int = 0\u001b[0m\n",
      "  logger.warn(\n",
      "/Users/silvanoquarto/Desktop/PROJECTS/Master_AI_Engineering/Healthcare-Cyber-Security-with-SARSA-DDQN/.venv/lib/python3.12/site-packages/gymnasium/utils/passive_env_checker.py:181: DeprecationWarning: \u001b[33mWARN: Current gymnasium version requires that `Env.reset` can be passed `options` to allow the environment initialisation to be passed additional information.\u001b[0m\n",
      "  logger.deprecation(\n",
      "/Users/silvanoquarto/Desktop/PROJECTS/Master_AI_Engineering/Healthcare-Cyber-Security-with-SARSA-DDQN/.venv/lib/python3.12/site-packages/gymnasium/utils/passive_env_checker.py:135: UserWarning: \u001b[33mWARN: The obs returned by the `reset()` method was expecting numpy array dtype to be int32, actual type: float64\u001b[0m\n",
      "  logger.warn(\n",
      "/Users/silvanoquarto/Desktop/PROJECTS/Master_AI_Engineering/Healthcare-Cyber-Security-with-SARSA-DDQN/.venv/lib/python3.12/site-packages/gymnasium/utils/passive_env_checker.py:159: UserWarning: \u001b[33mWARN: The obs returned by the `reset()` method is not within the observation space.\u001b[0m\n",
      "  logger.warn(f\"{pre} is not within the observation space.\")\n",
      "/Users/silvanoquarto/Desktop/PROJECTS/Master_AI_Engineering/Healthcare-Cyber-Security-with-SARSA-DDQN/.venv/lib/python3.12/site-packages/gymnasium/utils/passive_env_checker.py:135: UserWarning: \u001b[33mWARN: The obs returned by the `step()` method was expecting numpy array dtype to be int32, actual type: float64\u001b[0m\n",
      "  logger.warn(\n",
      "/Users/silvanoquarto/Desktop/PROJECTS/Master_AI_Engineering/Healthcare-Cyber-Security-with-SARSA-DDQN/.venv/lib/python3.12/site-packages/gymnasium/utils/passive_env_checker.py:159: UserWarning: \u001b[33mWARN: The obs returned by the `step()` method is not within the observation space.\u001b[0m\n",
      "  logger.warn(f\"{pre} is not within the observation space.\")\n",
      "/Users/silvanoquarto/Desktop/PROJECTS/Master_AI_Engineering/Healthcare-Cyber-Security-with-SARSA-DDQN/.venv/lib/python3.12/site-packages/gymnasium/utils/passive_env_checker.py:246: UserWarning: \u001b[33mWARN: The reward returned by `step()` must be a float, int, np.integer or np.floating, actual type: <class 'tuple'>\u001b[0m\n",
      "  logger.warn(\n",
      "/Users/silvanoquarto/Desktop/PROJECTS/Master_AI_Engineering/Healthcare-Cyber-Security-with-SARSA-DDQN/.venv/lib/python3.12/site-packages/gymnasium/utils/passive_env_checker.py:318: UserWarning: \u001b[33mWARN: No render modes was declared in the environment (env.metadata['render_modes'] is None or not defined), you may have trouble when calling `.render()`.\u001b[0m\n",
      "  logger.warn(\n",
      "2024-11-13 11:43:41.925 Python[39060:16942726] +[IMKClient subclass]: chose IMKClient_Modern\n",
      "2024-11-13 11:43:41.985 Python[39060:16942726] +[IMKInputSession subclass]: chose IMKInputSession_Modern\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Step 2:\n",
      "Action taken - Attack: 28, Defense: 1\n",
      "Reward: (0, 0)\n",
      "Terminated: False\n",
      "Truncated: False\n",
      "Info: {'moved': False}\n",
      "New Observation Shape: (3, 11)\n",
      "\n",
      "Step 3:\n",
      "Action taken - Attack: 17, Defense: 13\n",
      "Reward: (0, 0)\n",
      "Terminated: False\n",
      "Truncated: False\n",
      "Info: {'moved': False}\n",
      "New Observation Shape: (3, 11)\n",
      "\n",
      "Exploration completed!\n"
     ]
    },
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mThe Kernel crashed while executing code in the current cell or a previous cell. \n",
      "\u001b[1;31mPlease review the code in the cell(s) to identify a possible cause of the failure. \n",
      "\u001b[1;31mClick <a href='https://aka.ms/vscodeJupyterKernelCrash'>here</a> for more info. \n",
      "\u001b[1;31mView Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details."
     ]
    }
   ],
   "source": [
    "import gymnasium as gym\n",
    "import gym_idsgame\n",
    "import numpy as np\n",
    "from gym_idsgame.envs.idsgame_env import IdsGameRandomAttackV0Env\n",
    "\n",
    "env_name = \"idsgame-random-attack-v0\"\n",
    "if env_name not in gym.envs.registry:\n",
    "    gym.register(\n",
    "        id=env_name,\n",
    "        entry_point=\"gym_idsgame.envs.idsgame_env:IdsGameRandomAttackV0Env\",\n",
    "        kwargs={\"idsgame_config\": None, \"save_dir\": None, \"initial_state_path\": None}\n",
    "    )\n",
    "\n",
    "def explore_environment():\n",
    "    try:\n",
    "        env = gym.make(\"idsgame-random-attack-v0\")\n",
    "        \n",
    "        print(\"\\n=== Environment Information ===\")\n",
    "        print(f\"Observation Space Type: {type(env.observation_space)}\")\n",
    "        print(f\"Action Space Type: {type(env.action_space)}\")\n",
    "        print(f\"Action Space: {env.action_space}\")\n",
    "        \n",
    "        initial_obs, _ = env.reset()\n",
    "        print(\"\\n=== Initial Observation ===\")\n",
    "        print(f\"Type: {type(initial_obs)}\")\n",
    "        print(f\"Shape: {initial_obs.shape}\")\n",
    "        \n",
    "        print(\"\\n=== Testing Random Actions ===\")\n",
    "        for i in range(3):\n",
    "            attack_action = env.action_space.sample()\n",
    "            defense_action = env.action_space.sample()\n",
    "            action = (attack_action, defense_action)\n",
    "            \n",
    "            obs, reward, terminated, truncated, info = env.step(action)\n",
    "            \n",
    "            print(f\"\\nStep {i+1}:\")\n",
    "            print(f\"Action taken - Attack: {attack_action}, Defense: {defense_action}\")\n",
    "            print(f\"Reward: {reward}\")\n",
    "            print(f\"Terminated: {terminated}\")\n",
    "            print(f\"Truncated: {truncated}\")\n",
    "            print(f\"Info: {info}\")\n",
    "            print(f\"New Observation Shape: {obs.shape}\")\n",
    "            \n",
    "            try:\n",
    "                env.render()\n",
    "            except Exception as e:\n",
    "                print(f\"Rendering failed: {e}\")\n",
    "                \n",
    "            if terminated or truncated:\n",
    "                obs, _ = env.reset()\n",
    "        \n",
    "        env.close()\n",
    "        \n",
    "    except Exception as e:\n",
    "        print(f\"An error occurred: {str(e)}\")\n",
    "        print(f\"Available environments: {list(gym.envs.registry.keys())}\")\n",
    "        raise e\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    explore_environment()\n",
    "    print(\"\\nExploration completed!\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
